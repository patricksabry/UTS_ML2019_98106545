{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patricksabry/UTS_ML2019_ID98106545/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t4pltkfrUxv",
        "colab_type": "text"
      },
      "source": [
        "# First Impressions\n",
        "\n",
        "What is my chosen paper to read?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "What type of the main contribution the paper has made?\n",
        "\n",
        "A theory or proposition (revealing something, from unknown to known)\n",
        "A method or algorithm (inventing a technique, from undoable to doable)\n",
        "Before reading the main body of the paper, write down your first impression obtained from its abstract and short introduction.\n",
        "\n",
        "Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "\n",
        "Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list, compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "(During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78DedMVasniB",
        "colab_type": "text"
      },
      "source": [
        "# Review on RUM86 - LEARNING INTERNAL REPRESENTATIONS BY ERROR PROPAGATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jmHevss1Z7",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The following paper is a a critique on the seminal research work conducted by Hinton et al in 1985 on error propagation in artifical neural networks. The paper serves to expound the group's efforts in identifying the success of using back propagation to promote self learning internal representations in deep neural networks. The group's early work on generalised error minimization techniques paved the way for advancements in deep neural networks as know it today. This paper explores these techniques in detail and reinforces them with tangible examples using current technologies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFjdKtjN5Emr",
        "colab_type": "text"
      },
      "source": [
        "# Content \n",
        "\n",
        "In the realm of machine learning the solution domain has been well understood for simple two layer associative networks for quite some time. Such networks allow an input layer of data to be directly mapped to a set of output patterns, meaning there is no internal (hidden) representation to be interpreted. Despite generalising output patterns reasonably, these simple networks are beholden to the rules encoded into the input data by external forces and as such are unable to learn unorthodox mappings from input to output. The paper explores the limitations of two layer systems in solving more complicated problems such as the XOR problem, and how such problems can be solved through the learning of internal representations using gradient descent.\n",
        "\n",
        "The paper outlines in detail the inner machinations of this learning procedure they labelled the 'generalized detla rule'."
      ]
    }
  ]
}